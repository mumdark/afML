# 三、神经网络

**神经网络可以通过 torch.nn 包来构建**：


- 这是一个简单的前馈神经网络，它接收输入，让输入一个接着一个的通过一些层，最后给出输出。

![mnist.png](attachment:mnist.png)



**一个典型的神经网络训练过程包括以下几点：**
1. 定义一个包含可训练参数的神经网络

2. 迭代整个输入

3. 通过神经网络处理输入

4. 计算损失(loss)

5. 反向传播梯度到神经网络的参数

6. 更新网络的参数，典型的用一个简单的更新方法：weight = weight - learning_rate *gradient

**当我们通俗地解释神经网络的前向传播过程时，可以将其比作一个烹饪的步骤，让我们以做蛋糕为例：**

1. 当我们通俗地解释神经网络的前向传播过程时，可以将其比作一个烹饪的步骤，让我们以做蛋糕为例：

2. 输入数据：就像准备做蛋糕的原材料，比如蛋、面粉、糖等。

3. 权重和偏置初始化：我们可以将权重看作是蛋糕食谱中的每种原料所需的量，偏置则是一些额外的调味料。在这一步，我们给每个原材料（输入）和调味料（偏置）分配了一些初始值。

4. 线性变换：就像在蛋糕食谱中，根据配方按比例混合各种原材料，形成蛋糕的面糊。在神经网络中，我们将输入数据和权重矩阵相乘，然后加上偏置，得到每一层的输出。

5. 激活函数：激活函数就像是烘焙过程中的烤箱，它赋予网络一些非线性特性，使得神经网络可以学习和处理更复杂的模式。就像蛋糕在烤箱里发生变化一样，在这一步中，每层的输出通过激活函数得到激活后的输出。

6. 重复：这是一个重复的过程，就像连续进行了几次烘焙和叠加的步骤，通过多层网络层，逐渐提取出更高级别的特征，就像蛋糕逐渐成形。

7. 输出层：就像将烘焙好的蛋糕拿出烤箱，输出层产生最终的预测结果或分类结果。

8. 预测/分类：这就是我们等待的最终结果，就像最后得到一个美味的蛋糕。预测/分类结果可以是一个概率值（表示某个类别的可能性），或者直接是具体的类别标签。

**从数学的角度来看，我们可以用符号表示神经网络的前向传播过程。假设我们有一个输入向量 X，表示为 X = [x1, x2, ..., xn]，其中 xi 是输入的第 i 个特征。**

1. 输入数据：输入数据是神经网络的起点，它是一个向量 X，包含了原始的输入特征值。

2. 权重和偏置初始化：权重和偏置是神经网络学习过程中需要优化的参数。它们通常被表示为矩阵 W 和向量 b。

3. 线性变换：线性变换将输入数据 X 与权重矩阵 W 相乘，然后再加上偏置向量 b。这个过程可以表示为：*Z = W \* X + b*。其中，Z 是该层的输出。这个过程实际上就是一个线性变换，将输入数据投影到新的空间。

4. 激活函数：在线性变换后，我们会应用一个激活函数 f()，将 Z 映射到一个非线性的激活值 A。这个过程可以表示为：*A = f(Z)*。激活函数的作用是引入非线性性，允许神经网络学习更复杂的模式和特征。如果没有激活函数，多层神经网络就会退化为单个线性层，无法有效地拟合复杂的数据。

5. 重复：这一步骤会将上述线性变换和激活函数的过程在网络的每一层中重复进行，直到数据通过所有隐藏层，到达输出层。每一层的输出会成为下一层的输入。

6. 输出层：在到达输出层时，不再使用激活函数。输出层通常是一个线性层或特殊的激活函数（如 Softmax），以产生最终的预测或分类结果。

**每个过程的相对于输入的变化有以下意义：**

- 权重和偏置初始化：这些参数的初始值是随机选择的，神经网络的目标是通过训练过程来优化它们，使得网络能够准确地进行预测或分类。

- 线性变换：线性变换将输入数据投影到新的空间，通过权重和偏置的组合，改变了数据的表示形式，从而使网络可以在不同的方向上学习不同的特征。

- 激活函数：激活函数引入了非线性性，它对线性变换的输出进行了映射，使得网络可以学习复杂的、非线性的关系。

- 重复：多层神经网络通过重复上述过程，逐渐从原始输入中提取出更高级别的特征，从而使网络能够处理更复杂的数据。

- 输出层：最终输出层的结果是网络对输入数据的预测或分类。每个输出节点对应于一个类别或目标值，网络会输出与输入数据相对应的预测结果。

## 3.1 对与torch.nn的探索

```py
import torch.nn as nn
dir(nn)
dir(nn.Module)
help(nn.Module)
```


## 3.2 完成一个简单神经网络模型


### 一：定义神经网络


```py
# 该代码定义了一个简单的神经网络类Net
# 这个网络包含了卷积层、全连接层和激活函数，用于处理图像分类任务
class Net(nn.Module):   #定义了一个继承自nn.Module的类Net，这个类将作为神经网络的主体

    def __init__(self):    #1.定义了神经网络的各个层，类的构造方法，在实例化时会被调用
        super(Net, self).__init__()
        # 第一个卷积层，输入通道数为1（单通道灰度图像），输出通道数为6，卷积核大小为5x5
        self.conv1 = nn.Conv2d(1, 6, 5)
        # 第二个卷积层，输入通道数为6，输出通道数为16，卷积核大小为5x5
        self.conv2 = nn.Conv2d(6, 16, 5)
        # an affine operation: y = Wx + b
        # 第一个全连接层/仿射层，输入特征数为16x5x5（经过两次卷积和池化后的特征图大小），输出特征数为120
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        # 第二个全连接层/仿射层，输入特征数为120，输出特征数为84
        self.fc2 = nn.Linear(120, 84)
        # 第三个全连接层，输入特征数为84，输出特征数为10
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):   #2.定义神经网络的前向传播过程，当输入数据x经过网络层时，会调用这个方法来计算输出
        # 经过第一层卷积后，应用ReLU激活函数，然后进行最大池化操作（2x2的窗口），池化操作(Pooling)层是模仿人的视觉系统对数据进行降维
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        # 经过第二层卷积后，应用ReLU激活函数，然后进行最大池化操作
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        # 将特征张量展平成一维向量，为了后续的全连接层输入准备数据
        x = x.view(-1, self.num_flat_features(x))
        # 经过第一个全连接层，应用ReLU激活函数
        x = F.relu(self.fc1(x))
        # 经过第二个全连接层，应用ReLU激活函数
        x = F.relu(self.fc2(x))
        #经过第三个全连接层，得到最终输出
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):  #3.计算展平后的特征数（当数据通过卷积层和池化层处理后，会得到一个叫做特征图（Feature Map）的输出。特征图是一个多维数组，其中包含了经过卷积和池化操作后提取到的特征。在神经网络的后续处理中，通常会将特征图展平成一维向量，然后输入到全连接层进行进一步的处理。具体地说，对于一个特征图，如果其形状为 (C, H, W)，其中 C 是通道数，H 是高度，W 是宽度，那么展平后的特征数就是 C x H x W。展平后的特征数指的是将特征图转换为一维向量后，该向量的长度（元素个数）。这个长度决定了全连接层中的输入节点数。展平后的特征数很重要，因为它需要与全连接层的输入节点数匹配。如果不匹配，将无法将特征图的信息正确传递给全连接层，从而导致错误。所以，在构建神经网络时，需要特别注意每一层的输出和下一层的输入维度是否匹配。）
        size = x.size()[1:]  # 获取除了批次维度以外的所有维度信息
        num_features = 1 # 初始化特征数为1
        for s in size:           # 计算展平后的特征数，即各个维度的乘积
            num_features *= s
        return num_features
```
## 卷积层与全连接层、前向传播、

## 神经网络的卷积层和全连接层都是神经网络中常用的层级结构

***1.卷积层：***
- 卷积层是用于处理图像等具有局部相关性数据的一种层。它通过使用权重共享和局部感受野的方式，有效地捕捉输入数据的局部特征。
- 在卷积层中，使用一组小矩阵（称为卷积核或滤波器）对输入数据进行卷积运算。这些卷积核在输入数据上滑动，通过逐元素相乘并求和的方式，将输入数据的局部区域与卷积核进行卷积运算，从而捕捉不同的特征。
- 卷积层的权重是卷积核的参数，而偏置是一个常数项，每个卷积核都有一个对应的偏置。

**卷积层可以理解为局部特征提取层，通过滤波器对输入数据进行卷积操作，捕捉输入数据中的局部信息。**

**假设输入的shape为 [1,224,224,3] 经过strid=2,padding=same,窗口shape为 [7,7] 的卷积，得到shape为 [1,112,112,64] 的输出。解释下输入输出中shape的四个数字的含义，第一个代表batch，也就是图片的数量，一般输入的batch是多少，输出的batch是多少。第二和第三个表示图片（特征图）的长度和宽度，第四个表示的图片（特征图）的深度（可以理解为多个二维的像素矩阵叠加在一起）。具体的卷积的话，第一步可以用下图表示：**

![v2-885acb1197b3629c964e94d784c26dfc_720w.png](attachment:v2-885acb1197b3629c964e94d784c26dfc_720w.png)

**从图中可以看出，这时候我们的weight的深度也变为3了，也就是7X7X3个参数，然后这个滑窗在深度为3的图片上滑动，滑到的区域，也就是一个三维区域，在这个三维区域内对应的像素值与滑窗对应位置的权重相乘，然后将乘到的7X7X3个数字加起来作为我们输出特征图的一个位置的像素值。也就是说我们输出图的一个像素值，是由输入特征图的某个区域内所有的7X7X3个像素值经过线性运算得到的。**

***2.全连接层：***
- 全连接层是神经网络中的一种常见层级结构，也称为密集连接层或仿射层。
- 在全连接层中，每个神经元与上一层的所有神经元都有连接，这使得它可以学习到输入数据中任意特征之间的复杂关系。
- 全连接层的输出由上一层的所有神经元通过权重和偏置的组合来计算。每个连接都有一个权重，表示前一层的神经元对当前神经元的重要性。

**全连接层可以理解为全局特征合并层，它将前一层的所有神经元与当前层的每个神经元连接，学习和整合输入数据中所有的特征信息。**

**假设全连接层的输入是个4096维的列向量，一般我们把这个向量叫做特征向量（卷积层提取到的特征的输出），经过全连接层得到一个10维的列向量输出（也就是10分类每一类别的评分）。我们如果把输入和输出都看成一个个节点的话，节点与节点之间的关系可以用下图来表示：**

![v2-29ddad845957a3ee7a1eae9ef0e01392_720w.png](attachment:v2-29ddad845957a3ee7a1eae9ef0e01392_720w.png)

**可以看出，10个节点中每一个节点的输出都是通过4096个节点的输入得到的，也就是说，每一个输出节点受所有的输入节点影响，这样就会有 4096\times10 个连接，每个连接上都会对应一个权重，则全连接层要训练 4096\times10 个权重。之所以称之为全连接层，就是由于每一个输出节点与每一个输入节点都有连接。**


```py
# 简单看看，可以使用任何张量操作在前馈函数上
net = Net()
print(net)
```

### 查看神经网络中的所有可学习参数

1. net.parameters() 返回神经网络中的所有可学习参数（权重和偏置），这些参数是网络在训练过程中需要更新的

2. 对于返回的所有可学习参数（params），可以使用以下方式调用

- len(params): 打印神经网络中可学习参数的数量，即列表 params 的长度，即权重矩阵和偏置向量的总数

- params[0].size(): 打印神经网络中第一个参数（即第一个权重矩阵）的形状。这个形状是一个元组，用来描述权重矩阵的维度。例如，形状为 (6, 1, 5, 5) 表示第一个卷积层的权重矩阵是一个 4 维张量，具有 6 个输出通道、1 个输入通道，以及 5x5 的卷积核大小。

- params[0]: 打印神经网络中第一个参数（即第一个权重矩阵）的值。这会显示出权重矩阵的具体数值，以及它们是如何初始化的。这些值在训练过程中会不断更新以优化网络的性能。




```py
# 一个模型可训练的参数可以通过调用 net.parameters() 返回
params = list( net.parameters() )
print( len(params), "\n\n", params[0].size(), "\n\n", params[0] )
```


### 二：对神经网络进行前向传播


**自动微分（Automatic Differentiation），也称为自动求导，是一种用于计算函数导数的技术。在机器学习和深度学习中，我们经常需要计算函数相对于其输入的导数（梯度），以便优化模型参数或进行反向传播算法。**


```py
# 尝试随机生成一个 32x32 的输入
input = torch.randn(1, 1, 32, 32) #第一个 1 表示批次大小（此处为单个样本），第二个 1 表示输入通道数（灰度图像只有一个通道），以及 32, 32 分别表示图像的高度和宽度
out = net(input)
print( input, "\n\n\n", out )

torch.randn(4, 4)
```
### 三：真实label数据的处理及损失函数

```py
# 生成一个真实的数据标签
target = torch.randn(10)  #随机生成目标值（真实的数据标签）

# 查看输出结果out以及taget真实值的大小size，可以看到此时两个张量的size是不一致的
print(target.size(), "\n\n", out.size())

# 由于张量size不一致，修改target的size使其与out一致
target = target.view(1, -1)
target.size()

# 有一些不同的损失函数在 nn 包中，一个简单的损失函数就是 nn.MSELoss（均方误差）
criterion = nn.MSELoss()
loss = criterion( out, target )
print(loss
```

**计算图：**

举一个简单的例子来说明计算图的概念：

假设我们有以下数学表达式：*z = (x + y) * (y + 5)*

这个表达式可以用如下的计算图表示：


![%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-07-19%20143239.png](attachment:%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-07-19%20143239.png)


在这个计算图中，每个节点代表一个操作，如加法（+）和乘法（*），或者代表变量，如变量 x、y 和 5。边表示数据的流动路径，连接了操作和变量。

节点上的操作是按照计算图的顺序进行计算的。例如，在这个计算图中，首先计算 x 和 y 的和（+ 操作），然后将结果与 y 和 5 的和相乘（* 操作），得到最终的结果 z。

计算图的一个重要应用是计算梯度。在深度学习中，梯度用于更新模型的参数以最小化损失。通过计算图，可以利用反向传播算法计算相对于输入变量的梯度。通过将梯度从输出节点传播到输入节点，我们可以有效地计算出每个变量对于损失函数的梯度，从而进行参数更新和优化。

---
**运行完上方代码，如果你跟随损失到反向传播路径，可以使用它的 .grad_fn 属性，你将会看到一个这样的计算图：**

![%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-07-19%20143558.png](attachment:%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-07-19%20143558.png)

**根据描述，我们可以看出当前计算图的结构如下：**

1. 输入（input）经过卷积层（conv2d）后，通过ReLU激活函数（relu）进行非线性变换，再经过最大池化层（maxpool2d）进行下采样。
2. 下采样后的特征图再次经过卷积层和ReLU激活函数，再经过最大池化层进行进一步的特征提取和下采样。
3. 经过一系列的卷积、ReLU和最大池化操作后，将特征图展平成一个向量（view）。
4. 展平后的特征向量经过全连接层（linear）和ReLU激活函数，再经过一系列的全连接层和ReLU操作。
5. 最后，使用均方误差损失函数（MSELoss）计算预测值与真实值之间的差异，得到损失（loss）。

**所以，当我们调用 loss.backward()，整个图都会微分，而且所有的在图中的requires_grad=True 的张量将会让他们的 grad 张量累计梯度。**

```py
# 使用grad_fn属性来查看损失值的计算图，grad_fn属性是一个用于追踪梯度计算图的对象
print(loss.grad_fn,"\n")  # 打印loss.grad_fn会显示损失值所使用的函数，即MSELoss（均方误差损失函数）
print(loss.grad_fn.next_functions[0][0],"\n")  # next_functions属性是一个元组，用于存储计算图中下一个函数的信息,在这里，我们打印了next_functions[0][0]，它表示损失函数的下一个函数，即Linear（线性层）
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # 这里进一步打印了Linear层的下一个函数，即ReLU（修正线性单元）
```

- 以上代码通过打印grad_fn属性以及next_functions属性的相关信息，可以追踪计算图中的函数关系，了解损失值是如何通过前向传播过程计算得到的

### 四：梯度计算和反向传播

```py
#将之前所有的梯度清零
net.zero_grad()

#打印当前convi层偏置、权重参数的梯度
print(net.conv1.bias.grad,"\n")
print(net.conv1.weight.grad,"\n")

#进行反向传播
loss.backward()

#打印当前convi层偏置、权重参数的梯度
print(net.conv1.bias.grad, "\n")
print(net.conv1.weight.grad,"\n")
```

### 五：更新神经网络参数

**最简单的参数更新方法是 *随机梯度下降* ：**

**在这个规则中，权重（weight）通过减去学习率（learning rate）乘以梯度（gradient）来进行更新。**

**具体而言，对于每个权重值，梯度下降的更新步骤如下：**

- weight = weight - learning_rate * gradient

其中，weight 是待更新的权重值，learning_rate 是学习率，gradient 是相对于该权重的梯度值。

**通过应用这个更新规则，每次迭代时，权重会朝着减小梯度的方向进行调整，以最小化损失函数。学习率控制了每次更新的步长大小，较大的学习率可能导致不稳定的更新，而较小的学习率可能导致收敛速度较慢。**

**除了随机梯度下降（SGD）之外，还有许多其他常用的参数更新规则：**

1. 动量（Momentum）更新规则
2. 学习率衰减（Learning Rate Decay）更新规则
3. 自适应学习率方法

```py
# 我们可以使用 python 来实现随机梯度下降
# 当前梯度值（f.grad.data）
# sub_() 方法原地（in-place）地进行减法操作。原地操作是指直接修改原始对象而不创建新的对象，这样可以减少内存开销。
learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)
```

- **尽管如此，如果你是用神经网络，你想使用不同的更新规则，类似于 SGD, Nesterov-SGD, Adam, RMSProp, 等。为了让这可行，我们建立了一个小包：torch.optim 实现了所有的方法。使用它非常的简单。**

```py
# 使用torch.optim模块中的优化器来实现参数更新的步骤
import torch.optim as optim

# 创建一个优化器对象optimizer
#使用的是随机梯度下降（SGD）算法，并传入了模型的参数net.parameters()和学习率lr=0.01
optimizer = optim.SGD(net.parameters(), lr=0.01)

# 在训练循环中，按照以下步骤进行参数更新
optimizer.zero_grad()   # 清零梯度
output = net(input) #前向传播
loss = criterion(output, target) #计算损失函数
loss.backward() #调用loss.backward()执行反向传播
optimizer.step()    # 调用optimizer.step()来执行参数更新
```